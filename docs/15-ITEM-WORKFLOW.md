# 15-Item Workflow Guide

Complete guide to the enhanced 15-item workflow with intelligent selection and daily limits.

## Overview

The system now processes up to **15 high-quality items** per run using intelligent tiered selection and content diversity, while enforcing daily safety limits to prevent overwhelming the human approver or your Twitter feed.

---

## ğŸ¯ Why 15 Items?

### The Strategy
- **Quality through Selection**: Send 15 candidates, approve best 5-8
- **Learning & Calibration**: More data to understand what works
- **Content Diversity**: Ensure variety across types and sources
- **Safety Net**: Even if some scores are inflated, human catches it

### Expected Workflow
```
15 items generated by Opus
â†“
Human reviews in batches
â†“
Approves 5-8 best posts (~30-50% approval rate)
â†“
Twitter gets high-quality, diverse content
```

---

## ğŸ”„ Complete Flow

### 1. Scraping (Automatic)
```
Every 60 minutes (configurable):
â”œâ”€ Crawl all active sources
â”œâ”€ Extract content, metadata, keywords
â”œâ”€ Generate content hashes for deduplication
â””â”€ Store in Supabase
```

### 2. Scoring (Automatic)
```
For each scraped article:
â”œâ”€ Calculate relevance (0.0-1.0)
â”‚  â”œâ”€ Keyword matching (40%)
â”‚  â”œâ”€ Title relevance (30%)
â”‚  â”œâ”€ Content quality (20%)
â”‚  â””â”€ Freshness (10%)
â””â”€ Store score in database
```

### 3. Intelligent Selection (Automatic)
```
Retrieve unprocessed content:
â”œâ”€ Filter by min_relevance (default: 0.5)
â”œâ”€ Apply tiered selection:
â”‚  â”œâ”€ Tier 1 (â‰¥0.8): Top 5-6 excellent items
â”‚  â”œâ”€ Tier 2 (0.6-0.8): 6-7 quality items with diversity
â”‚  â””â”€ Tier 3 (0.5-0.6): 2-3 good items to fill quota
â”œâ”€ Ensure category distribution
â””â”€ Select exactly 15 items (or remaining quota)
```

### 4. Daily Limit Check (Automatic)
```
Before processing:
â”œâ”€ Query jobs initiated today
â”œâ”€ Check against DAILY_POST_LIMIT (default: 30)
â”œâ”€ If limit reached â†’ stop and notify
â””â”€ If quota available â†’ proceed with min(15, remaining_quota)
```

### 5. Opus Processing (Automatic)
```
For each selected item:
â”œâ”€ Categorize content type
â”œâ”€ Prepare Opus-ready payload
â”œâ”€ Initiate Opus job
â”œâ”€ Execute with content data
â”œâ”€ Poll until complete
â””â”€ Store results in database
```

### 6. Human Approval (Manual in Opus)
```
Approver reviews in Opus:
â”œâ”€ Sees 15 generated posts
â”œâ”€ Reviews quality and relevance
â”œâ”€ Approves best 5-8 posts
â””â”€ Rejects rest
```

### 7. Publishing (Automatic in Opus)
```
For approved posts:
â”œâ”€ Opus posts to Twitter/X
â”œâ”€ External system polls for completion
â””â”€ Logs success in database
```

---

## âš™ï¸ Configuration

### Environment Variables

```bash
# Core Processing Settings
MAX_ITEMS_PER_RUN=15              # Items to send to Opus per run
MIN_RELEVANCE_SCORE=0.5           # Minimum quality threshold
DAILY_POST_LIMIT=30               # Max jobs per day (safety)

# Selection Strategy
ENABLE_CONTENT_DIVERSITY=true     # Balance across categories
IMMEDIATE_PROCESSING=true         # Process right after scraping

# Timing
SCRAPING_INTERVAL_MINUTES=60      # How often to scrape
```

### Tuning Guidelines

#### Conservative Approach
```bash
MAX_ITEMS_PER_RUN=10
MIN_RELEVANCE_SCORE=0.6
DAILY_POST_LIMIT=25
```
- Best for: Limited time for approvals, tight budget
- Results: Higher quality, less volume

#### Aggressive Approach  
```bash
MAX_ITEMS_PER_RUN=20
MIN_RELEVANCE_SCORE=0.45
DAILY_POST_LIMIT=40
```
- Best for: Learning phase, team approvals, multi-platform
- Results: More options, more review time needed

#### Recommended Balanced
```bash
MAX_ITEMS_PER_RUN=15
MIN_RELEVANCE_SCORE=0.5
DAILY_POST_LIMIT=30
```
- Best for: Most use cases
- Results: Good variety, manageable volume

---

## ğŸ¨ Intelligent Selection Explained

### Tiered Quality Approach

#### Tier 1: Excellence (â‰¥ 0.8)
- **Priority**: Must include
- **Allocation**: Up to 40% of batch (~5-6 items)
- **Logic**: Highest quality content that should definitely be included
- **Example**: Breaking news, highly relevant thought leadership

#### Tier 2: Quality (0.6 - 0.8)
- **Priority**: Should include with diversity
- **Allocation**: Up to 50% of batch (~6-7 items)
- **Logic**: High quality with category balancing
- **Example**: Good industry news, solid case studies

#### Tier 3: Good (0.5 - 0.6)
- **Priority**: Fill remaining slots
- **Allocation**: Remaining quota (~2-3 items)
- **Logic**: Acceptable quality to reach target volume
- **Example**: Decent articles that passed threshold

### Content Diversity

The system ensures variety by:

1. **Category Balancing**: Equal distribution across industry_news, thought_leadership, case_study
2. **Source Variety**: Avoids over-selecting from single source
3. **Theme Diversity**: Keywords and topics vary
4. **Quality Mix**: Not all tier 1 or all tier 3

**Example Distribution:**
```
15 selected items:
â”œâ”€ 5 Tier 1 (Excellent)
â”‚  â”œâ”€ 2 industry_news
â”‚  â”œâ”€ 2 thought_leadership
â”‚  â””â”€ 1 case_study
â”œâ”€ 7 Tier 2 (Quality with diversity)
â”‚  â”œâ”€ 3 industry_news
â”‚  â”œâ”€ 2 thought_leadership
â”‚  â””â”€ 2 case_study
â””â”€ 3 Tier 3 (Good to fill)
   â”œâ”€ 1 industry_news
   â”œâ”€ 1 thought_leadership
   â””â”€ 1 case_study
```

---

## ğŸ“Š Monitoring & Analytics

### Daily Quota Tracking

```bash
# Check current quota
python main.py status

# Output shows:
ğŸ“Š Daily Quota:
  - Jobs Today: 12/30 (40.0%)
  - Remaining: 18
```

### Content Quality Distribution

```bash
# Status command shows quality breakdown
ğŸ“„ Content Status:
  - Unprocessed: 45
  - High Quality (â‰¥0.7): 18
  - Good Quality (0.5-0.7): 22
  - Lower Quality (<0.5): 5
```

### Database Queries

```sql
-- Today's job count
SELECT COUNT(*) FROM opus_jobs 
WHERE initiated_at >= CURRENT_DATE;

-- Quality distribution of unprocessed content
SELECT 
  CASE 
    WHEN relevance_score >= 0.8 THEN 'Tier 1 (Excellent)'
    WHEN relevance_score >= 0.6 THEN 'Tier 2 (Quality)'
    WHEN relevance_score >= 0.5 THEN 'Tier 3 (Good)'
    ELSE 'Below Threshold'
  END as tier,
  COUNT(*) as count
FROM scraped_content
WHERE is_processed = false
GROUP BY tier
ORDER BY tier;

-- Approval rate analysis
SELECT 
  DATE(initiated_at) as date,
  COUNT(*) as jobs_initiated,
  SUM(CASE WHEN status = 'COMPLETED' THEN 1 ELSE 0 END) as completed
FROM opus_jobs
GROUP BY DATE(initiated_at)
ORDER BY date DESC
LIMIT 7;
```

---

## ğŸ¯ Best Practices

### Daily Routine

**Morning Check:**
```bash
python main.py status
# Review quota usage, check quality distribution
```

**Approve in Opus:**
- Log in 2-3 times per day
- Review batches of ~15 posts
- Approve best 5-8 from each batch
- Maintain ~30-50% approval rate

**Evening Review:**
```bash
python main.py status
# Check how many posts went out
# Review engagement (in Twitter analytics)
```

### Optimization Tips

1. **Track Approval Patterns**
   - Which relevance scores get approved?
   - Which content types perform better?
   - Which sources are most valuable?

2. **Adjust Thresholds**
   - If approval rate < 30% â†’ raise MIN_RELEVANCE_SCORE
   - If approval rate > 80% â†’ lower threshold or increase volume
   - If hitting daily limit â†’ raise limit or reduce scraping frequency

3. **Content Quality**
   - Review rejected posts to understand why
   - Refine keyword lists for better relevance scoring
   - Add/remove sources based on quality

### Scaling Strategies

**Week 1-2: Learning**
```bash
MAX_ITEMS_PER_RUN=15
MIN_RELEVANCE_SCORE=0.5
DAILY_POST_LIMIT=30
# Goal: Understand patterns
```

**Week 3-4: Optimization**
```bash
# Based on data, adjust thresholds
# Example: If scores 0.5-0.6 rarely get approved:
MIN_RELEVANCE_SCORE=0.6
MAX_ITEMS_PER_RUN=12
```

**Week 5+: Efficiency**
```bash
# Fine-tuned based on your specific patterns
# Example optimized settings:
MIN_RELEVANCE_SCORE=0.65
MAX_ITEMS_PER_RUN=10
DAILY_POST_LIMIT=25
```

---

## ğŸš¨ Troubleshooting

### Issue: Daily Limit Reached Too Early

**Symptoms:**
```
âš ï¸  Daily limit reached! Cannot process more items today.
```

**Solutions:**
1. Increase `DAILY_POST_LIMIT`
2. Reduce scraping frequency
3. Raise `MIN_RELEVANCE_SCORE` to be more selective
4. Check for stuck/failed jobs counting against limit

### Issue: Too Many Low-Quality Items

**Symptoms:**
- Approval rate < 20%
- Most tier 3 items getting rejected

**Solutions:**
1. Raise `MIN_RELEVANCE_SCORE` to 0.6 or 0.65
2. Refine keyword lists in `processor.py`
3. Review and adjust source quality
4. Check if categorization is accurate

### Issue: Not Enough Content to Process

**Symptoms:**
```
No high-relevance content found for processing
```

**Solutions:**
1. Lower `MIN_RELEVANCE_SCORE`
2. Add more content sources
3. Increase scraping frequency
4. Check if sources are being scraped successfully

### Issue: Overwhelming Approval Queue

**Symptoms:**
- 50+ posts waiting for approval
- Can't keep up with review volume

**Solutions:**
1. Reduce `MAX_ITEMS_PER_RUN`
2. Increase `MIN_RELEVANCE_SCORE`
3. Review less frequently but in bigger batches
4. Consider team approvals

---

## ğŸ“ˆ Success Metrics

### Track These KPIs

1. **Approval Rate**: Target 30-50%
   - Too low â†’ wasting Opus jobs
   - Too high â†’ missing good content

2. **Daily Quota Usage**: Target 50-80%
   - Gives room for exceptional days
   - Not wasting available capacity

3. **Content Diversity**: Target balanced distribution
   - Check category mix in approved posts
   - Ensure variety in feed

4. **Engagement**: Track Twitter analytics
   - Which content types perform best?
   - What time of day gets best engagement?

5. **Efficiency**: Time spent on approvals
   - Target: 10-15 minutes per session
   - 2-3 sessions per day

---

## ğŸ“ Advanced Usage

### Manual Override

```bash
# Process specific quality tier
python main.py process --min-relevance 0.7 --max-items 5

# Emergency: bypass daily limit (not recommended)
# Temporarily increase in .env, then:
python main.py process
```

### Custom Selection

Edit `src/processor.py` to customize:
- Tier boundaries
- Diversity algorithm
- Category weights
- Source preferences

### A/B Testing

Run two configurations and compare:
```bash
# Configuration A (morning)
MAX_ITEMS_PER_RUN=10 python main.py process

# Configuration B (afternoon) 
MAX_ITEMS_PER_RUN=20 python main.py process

# Compare approval rates and engagement
```

---

## ğŸ“ Summary

The 15-item workflow provides:
- âœ… **Quality through selection** - human picks best from 15
- âœ… **Learning opportunity** - see what Opus generates across quality levels
- âœ… **Content diversity** - automatic category balancing
- âœ… **Safety limits** - daily caps prevent overwhelm
- âœ… **Intelligent tiering** - excellence prioritized, good content fills quota
- âœ… **Flexibility** - configurable at every level

**Remember**: The goal is sustainable, high-quality content marketing at scale. The 15-item approach gives you options while maintaining quality control. ğŸ¯
